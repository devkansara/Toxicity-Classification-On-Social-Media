{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 6 class-labels\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "# reading the data\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "\n",
    "# assigning comment and id to X\n",
    "cols = [0,1]\n",
    "X = data[data.columns[cols]]\n",
    "\n",
    "\n",
    "# assigning class-labels to Y\n",
    "cols1 = [2,3,4,5,6,7]\n",
    "Y = data[data.columns[cols1]]\n",
    "\n",
    "\n",
    "# splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only comment from X\n",
    "\n",
    "train_comment = X_train[\"comment_text\"]\n",
    "test_comment = X_test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "\n",
    "# using tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_features)\n",
    "\n",
    "# fit and transform\n",
    "tokenizer.fit_on_texts(list(train_comment))\n",
    "\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_comment)\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than 97% of comments have a max length of 200 words, thus padding all comments for this length\n",
    "max_length = 200\n",
    "\n",
    "X_train_new = pad_sequences(train_tokenized, maxlen = max_length)\n",
    "X_test_new = pad_sequences(test_tokenized, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# building lstm model using different layers\n",
    "\n",
    "def my_classifier():\n",
    "    inp = Input(shape = (max_length, ))\n",
    "    \n",
    "    embed_size = 128\n",
    "    # max_features = 20000\n",
    "    \n",
    "    # embedding layer to convert 2D input to 3D\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    \n",
    "    # lstm layer\n",
    "    x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
    "    \n",
    "    # maxpool layer\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    # dropout layer with rate=0.25\n",
    "    x = Dropout(.25)(x)\n",
    "    \n",
    "    # dense layer with sigmoid activation function\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    # generating the model\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# calling the function to generate the neural network\n",
    "model = my_classifier()\n",
    "\n",
    "model.fit(X_train_new, y_train.values, batch_size=32, epochs=5)\n",
    "y_pred = model.predict(X_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating binary values based on a threshold value\n",
    "\n",
    "# the threshold value was obtained by elbow method\n",
    "\n",
    "y_pred1=[[None for i in range(6)] for j in range(len(y_pred))] \n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(6):\n",
    "        if y_pred[i][j]<0.527:\n",
    "            y_pred1[i][j]=0\n",
    "        else:\n",
    "            y_pred1[i][j]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 class-labels\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "print(classification_report(y_test.values,y_pred1,target_names=label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating overall accuracy by checking the predicted output against the given output\n",
    "\n",
    "a=y_test.values.tolist()\n",
    "b=y_pred1\n",
    "count=0\n",
    "for i in range(len(y_test)):\n",
    "    if a[i] == b[i]:\n",
    "        count+=1\n",
    "print(\"Accuracy: \",count/len(y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "\n",
    "print(\"Time: \",(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
